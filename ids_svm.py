# -*- coding: utf-8 -*-
"""IDS_SVM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mq8YPm2xcSSlC-QobGC875GXcblBj-d4

## Importing
"""

import pandas as pd
import numpy as np
import sklearn
import sys

!pip install tensorflow==1.14.0

"""## Version Check"""

print("Pandas:", pd.__version__)
print("Numpy:", np.__version__)
print("Sklearn:", sklearn.__version__)
print("sys:", sys.version)

"""## Load the Dataset"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/My\ Drive/smart\ ids/ids/

ls

#Setting the column names to the dataset
Columns = ["duration", "protocol_type", "service", "flag", "src_bytes",
           "dst_bytes", "land", "wrong_fragment", "urgent", "hot", "num_failed_logins",
           "logged_in", "num_compromised", "root_shell", "su_attempted", "num_root",
           "num_file_creations", "num_shells", "num_access_files", "num_outbound_cmds",
           "is_host_login", "is_guest_login", "count", "srv_count", "serror_rate",
           "srv_serror_rate", "rerror_rate", "srv_rerror_rate", "same_srv_rate",
           "diff_srv_rate", "srv_diff_host_rate", "dst_host_count", "dst_host_srv_count",
           "dst_host_same_srv_rate", "dst_host_diff_srv_rate", "dst_host_same_src_port_rate",
           "dst_host_srv_diff_host_rate", "dst_host_serror_rate", "dst_host_srv_serror_rate",
           "dst_host_rerror_rate", "dst_host_srv_rerror_rate", "label"]

train_set = pd.read_csv("datasets/KDD/KDDTrain+_2.csv", header = None, names = Columns)
test_set = pd.read_csv("datasets/KDD/KDDTest+_2.csv", header = None, names = Columns)

print ("Dataset Loaded")

"""## Sample Views of Loaded datasets"""

print("Training Set")
train_set.head(5)

print("Testing Set")
test_set.head(5)

"""## Dimensions of loaded datasets"""

print('Training set shape:',train_set.shape)
print('Test set shape:',test_set.shape)

"""## Dataset Statistical Summary"""

train_set.describe()

test_set.describe()

"""## Distribution of Labels on the datasets"""

print("Label distribution on Training Set:")
print(train_set['label'].value_counts())

print("Label distribution on Test Set:")
print(test_set['label'].value_counts())

"""# Step 1: Data Preprocessing

## Finding the categorical Information
"""

print("Training set - categorical information:\n")
for column in train_set.columns:
    if train_set[column].dtype == 'object':
        category = len(train_set[column].unique())
        print("Feature '{column}' has {category} categories".format(column=column, category=category))

print("Test set - categorical information:\n")
for column in test_set.columns:
    if test_set[column].dtype == 'object':
        category = len(test_set[column].unique())
        print("Feature '{column}' has {category} categories".format(column=column, category=category))

"""#### By looking at the categorical information, we can clearly understand that the distribution is fairly even. Hence we need to make dummies for all the categories.

#### In total, 3+70+11 = 84 dummies are needed

### Creating 2D Arrays for categorical data
"""

CatColumns = ['protocol_type', 'service', 'flag']
Train_CatValues = train_set[CatColumns]
Test_CatValues = test_set[CatColumns]
print("Categorical Values --> 2D Array")

print("Training Set:")
Train_CatValues.head()

print("Testing Set:")
Test_CatValues.head()

"""### Creation of Dummies for Training Set"""

TrainProtocols = sorted(train_set.protocol_type.unique())
TrainUniqueProtocol = ["Protocol Type:" + x for x in TrainProtocols]

TrainServices = sorted(train_set.service.unique())
TrainUniqueService = ["Service:" + x for x in TrainServices]

TrainFlags = sorted(train_set.flag.unique())
TrainUniqueFlag = ["Flag:" + x for x in TrainFlags]

TrainDummyColumns = TrainUniqueProtocol + TrainUniqueService + TrainUniqueFlag
print("Dummy columns of training set:")
print(TrainDummyColumns)

"""### Creation of Dummies for Test Set

# New Section
"""

# Though not required
TestProtocols = sorted(test_set.protocol_type.unique())
TestUniqueProtocol = ["Protocol Type:" + x for x in TestProtocols]

TestServices = sorted(test_set.service.unique())
TestUniqueService = ["Service:" + x for x in TestServices]

TestFlags = sorted(test_set.flag.unique())
TestUniqueFlag = ["Flag:" + x for x in TestFlags]

TestDummyColumns = TestUniqueProtocol + TestUniqueService + TestUniqueFlag
print("Dummy columns of test set:")
print(TestDummyColumns)

print("Length of TestDummyColumns: " + str(len(TestDummyColumns)))
print("Length of TrainDummyColumns: " + str(len(TrainDummyColumns)))

"""### Encoding categorical data into integers"""

from sklearn.preprocessing import LabelEncoder

# Training Set
Train_CatValuesEnc = Train_CatValues.apply(LabelEncoder().fit_transform)
print("Encoded Categorical values of Training Set:")
print(Train_CatValuesEnc.head())

# Test Set
Test_CatValuesEnc = Test_CatValues.apply(LabelEncoder().fit_transform)
print("Encoded Categorical values of Training Set:")
print(Test_CatValuesEnc.head())

"""### One Hot Encoding"""

from sklearn.preprocessing import OneHotEncoder

# Training Set
OHE = OneHotEncoder()
Train_CatValuesOHE = OHE.fit_transform(Train_CatValuesEnc)
Train_CatData = pd.DataFrame(Train_CatValuesOHE.toarray(), columns = TrainDummyColumns)
Train_CatData.head()

# Test Set
Test_CatValuesOHE = OHE.fit_transform(Test_CatValuesEnc)
Test_CatData = pd.DataFrame(Test_CatValuesOHE.toarray(), columns = TestDummyColumns)
Test_CatData.head()

"""### Balancing Training and Test Set"""

TrS = train_set['service'].tolist()
TeS = test_set['service'].tolist()
diff = list(set(TrS) - set(TeS))
diff=["Service: " + x for x in diff]
diff

for each in diff:
    Test_CatData[each] = 0

Test_CatData.shape

# Recollecting the shapes for our understading
print (train_set.shape)
print (test_set.shape)

"""### Combining Categorical data with non-categorical data"""

# Training Set
TrainSet = train_set.join(Train_CatData)
TrainSet.drop('flag', axis=1, inplace=True)
TrainSet.drop('protocol_type', axis=1, inplace=True)
TrainSet.drop('service', axis=1, inplace=True)

print("Shape of the Final Training Set: " + str(TrainSet.shape))

# Test Set
TestSet = test_set.join(Test_CatData)
TestSet.drop('flag', axis=1, inplace=True)
TestSet.drop('protocol_type', axis=1, inplace=True)
TestSet.drop('service', axis=1, inplace=True)

print("Shape of the Final Test Set: " + str(TestSet.shape))

"""## Splitting Dataset

Replacing every attack label as follows:

0 = normal,

1 = DoS,

2 = Probe,

3 = R2L and

4 = U2R
"""

print(TrainSet['label'].head())

# Training Set
temp = TrainSet['label']
TrainLabel = temp.replace({'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1,
                          'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1,
                          'worm': 1, 'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,
                          'saint' : 2, 'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,
                          'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,
                          'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,
                          'httptunnel': 3, 'buffer_overflow': 4,'loadmodule': 4,'perl': 4,
                          'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})
TrainSet['label'] = TrainLabel
print(TrainSet['label'].head())

print(TestSet['label'].head())

# Test Set
temp = TestSet['label']
TestLabel = temp.replace({'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1,
                          'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1,
                          'worm': 1, 'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,
                          'saint' : 2, 'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,
                          'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,
                          'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,
                          'httptunnel': 3, 'buffer_overflow': 4,'loadmodule': 4,'perl': 4,
                          'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})
TestSet['label'] = TestLabel
print(TestSet['label'].head())

Dos = [2,3,4]
Probe = [1,3,4]
R2L = [1,2,4]
U2R = [1,2,3]

# Training Set
TrainDos = TrainSet[~TrainSet['label'].isin(Dos)];
TrainProbe = TrainSet[~TrainSet['label'].isin(Probe)];
TrainR2L = TrainSet[~TrainSet['label'].isin(R2L)];
TrainU2R = TrainSet[~TrainSet['label'].isin(U2R)];

print("Training Set:")
print("Dimensions of DoS Training Set: ", TrainDos.shape)
print("Dimensions of Probe Training Set: ", TrainProbe.shape)
print("Dimensions of R2L Training Set: ", TrainR2L.shape)
print("Dimensions of U2R Training Set: ", TrainU2R.shape)

# Test Set
TestDos = TestSet[~TestSet['label'].isin(Dos)];
TestProbe = TestSet[~TestSet['label'].isin(Probe)];
TestR2L = TestSet[~TestSet['label'].isin(R2L)];
TestU2R = TestSet[~TestSet['label'].isin(U2R)];

print("Testing Set:")
print("Dimensions of DoS Test Set: ", TestDos.shape)
print("Dimensions of Probe Test Set: ", TestProbe.shape)
print("Dimensions of R2L Test Set: ", TestR2L.shape)
print("Dimensions of U2R Test Set: ", TestU2R.shape)

"""# Step 2: Feature Scaling

Split dataframes into X & Y

Assign X as a dataframe of feautures and Y as a series of outcome variables
"""

#Training Set
X_TrainDos = TrainDos.drop('label',1)
Y_TrainDos = TrainDos.label
X_TrainProbe = TrainProbe.drop('label',1)
Y_TrainProbe = TrainProbe.label
X_TrainR2L = TrainR2L.drop('label',1)
Y_TrainR2L = TrainR2L.label
X_TrainU2R = TrainU2R.drop('label',1)
Y_TrainU2R = TrainU2R.label

#X_TrainDos.head()
#Y_TrainDos.head()

type(X_TrainDos)

train_dos = Y_TrainDos.to_numpy()
train_probe = Y_TrainProbe.to_numpy()
train_r2l = Y_TrainR2L.to_numpy()
train_u2r = Y_TrainU2R.to_numpy()
res_train_y = np.concatenate((train_dos,train_probe,train_r2l,train_u2r),axis =0)

#Test Set
X_TestDos = TestDos.drop('label',1)
Y_TestDos = TestDos.label
X_TestProbe = TestProbe.drop('label',1)
Y_TestProbe = TestProbe.label
X_TestR2L = TestR2L.drop('label',1)
Y_TestR2L = TestR2L.label
X_TestU2R = TestU2R.drop('label',1)
Y_TestU2R = TestU2R.label

#X_TestDos.head()
#Y_TestDos.head()

test_dos = Y_TestDos.to_numpy()
test_probe = Y_TestProbe.to_numpy()
test_r2l = Y_TestR2L.to_numpy()
test_u2r = Y_TestU2R.to_numpy()
res_test_y = np.concatenate((test_dos,test_probe,test_r2l,test_u2r),axis =0)

TrainColumnNames = list(X_TrainDos)
TestColumnNames = list(X_TestDos)

print(str(len(TrainColumnNames)) + " Columns in Training Set:\n")
print(TrainColumnNames)
print("\n\n")
print(str(len(TestColumnNames)) + " Columns in Test Set:\n")
print(TestColumnNames)

"""### Scaling Dataframes using StandardScaler()"""

from sklearn import preprocessing

# Training Set
scaler = preprocessing.StandardScaler().fit(X_TrainDos)
X_TrainDos = scaler.transform(X_TrainDos)

scaler = preprocessing.StandardScaler().fit(X_TrainProbe)
X_TrainProbe = scaler.transform(X_TrainProbe)

scaler = preprocessing.StandardScaler().fit(X_TrainR2L)
X_TrainR2L = scaler.transform(X_TrainR2L)

scaler = preprocessing.StandardScaler().fit(X_TrainU2R)
X_TrainU2R = scaler.transform(X_TrainU2R)

# Testing Set
scaler = preprocessing.StandardScaler().fit(X_TestDos)
X_TestDos = scaler.transform(X_TestDos)

scaler = preprocessing.StandardScaler().fit(X_TestProbe)
X_TestProbe = scaler.transform(X_TestProbe)

scaler = preprocessing.StandardScaler().fit(X_TestR2L)
X_TestR2L = scaler.transform(X_TestR2L)

scaler = preprocessing.StandardScaler().fit(X_TestU2R)
X_TestU2R = scaler.transform(X_TestU2R)

res_train= np.concatenate((X_TrainDos, X_TrainProbe,X_TrainR2L,X_TrainU2R), axis=0)
res_test = np.concatenate((X_TestDos, X_TestProbe,X_TestR2L,X_TestU2R), axis=0)

type(X_TrainDos)

X_TestDos.shape

print(X_TrainDos.std(axis=0))

print(X_TrainProbe.std(axis=0))

print(X_TrainU2R.std(axis=0))

print(X_TrainR2L.std(axis=0))

lstm_output_size = 70

cnn = Sequential()
cnn.add(Convolution1D(64, 3, border_mode="same",activation="relu",input_shape=(122, 1)))
cnn.add(MaxPooling1D(pool_length=(2)))
cnn.add(LSTM(lstm_output_size))
cnn.add(Dropout(0.1))
cnn.add(Dense(5, activation="softmax"))

# define optimizer and objective, compile cnn

cnn.compile(loss="categorical_crossentropy", optimizer="adam",metrics=['accuracy'])

"""# Step 3: Feature Selection"""

#SelectPercentile: removes all but a user-specified highest scoring percentage of features
#f_classif: ANOVA F-value between label/feature for classification tasks.
from sklearn.feature_selection import SelectPercentile, f_classif

# Training Set
np.seterr(divide='ignore', invalid='ignore');
selector=SelectPercentile(f_classif, percentile=99.9)
X_TrainDosNew = selector.fit_transform(X_TrainDos, Y_TrainDos)
X_TrainDosNew.shape



X_TrainDosNew

# Testing Set
np.seterr(divide='ignore', invalid='ignore');
selector=SelectPercentile(f_classif, percentile=99.9)
X_TestDosNew = selector.fit_transform(X_TestDos, Y_TestDos)
X_TestDosNew.shape

#Dos
true=selector.get_support()
ColIndex_Dos=[i for i, x in enumerate(true) if x]
ColName_Dos=list( TrainColumnNames[i] for i in ColIndex_Dos )
ColName_Dos

# Probe
X_TrainProbeNew = selector.fit_transform(X_TrainProbe, Y_TrainProbe)
X_TrainProbeNew.shape

# Probe
X_TestProbeNew = selector.fit_transform(X_TestProbe, Y_TestProbe)
X_TestProbeNew.shape

true=selector.get_support()
ColIndex_Probe=[i for i, x in enumerate(true) if x]
ColName_Probe=list( TrainColumnNames[i] for i in ColIndex_Probe )
ColName_Probe

# U2R
X_TrainU2RNew = selector.fit_transform(X_TrainU2R, Y_TrainU2R)
X_TrainU2RNew.shape

# U2R
X_TestU2RNew = selector.fit_transform(X_TestU2R, Y_TestU2R)
X_TestU2RNew.shape

true=selector.get_support()
ColIndex_U2R=[i for i, x in enumerate(true) if x]
ColName_U2R=list( TrainColumnNames[i] for i in ColIndex_U2R )
ColName_U2R

# R2L
X_TrainR2LNew = selector.fit_transform(X_TrainR2L, Y_TrainR2L)
X_TrainR2LNew.shape

# R2L
X_TestR2LNew = selector.fit_transform(X_TestR2L, Y_TestR2L)
X_TestR2LNew.shape

true=selector.get_support()
ColIndex_R2L=[i for i, x in enumerate(true) if x]
ColName_R2L=list( TrainColumnNames[i] for i in ColIndex_R2L )
ColName_R2L



res_train_an= np.concatenate((X_TrainDosNew, X_TrainProbeNew,X_TrainR2LNew,X_TrainU2RNew), axis=0)
res_test_an = np.concatenate((X_TestDosNew, X_TestProbeNew,X_TestR2LNew,X_TestU2RNew), axis=0)

"""### Features selected by Univariate Feature Selection"""

print("Features selected for Dos:")
print(ColName_Dos)
print()

print("Features selected for Probe:")
print(ColName_Probe)
print()

print("Features selected for R2L:")
print(ColName_R2L)
print()

print("Features selected for U2R:")
print(ColName_U2R)

"""## Ranking Features using Recursive Feature Elimination"""

from sklearn.feature_selection import RFE
from sklearn.tree import DecisionTreeClassifier

classifier = DecisionTreeClassifier(random_state=0) # Classifier Creation

RankFeatures = RFE(classifier, n_features_to_select=1)

# Dos
RankFeatures.fit(X_TrainDosNew, Y_TrainDos)

print ("Dos Features based on their rank:")
print (sorted(zip(map(lambda x: round(x, 4), RankFeatures.ranking_), ColName_Dos)))

# Probe
RankFeatures.fit(X_TrainProbeNew, Y_TrainProbe)

print ("Probe Features based on their rank:")
print (sorted(zip(map(lambda x: round(x, 4), RankFeatures.ranking_), ColName_Probe)))

# U2R
RankFeatures.fit(X_TrainU2RNew, Y_TrainU2R)

print ("U2R Features based on their rank:")
print (sorted(zip(map(lambda x: round(x, 4), RankFeatures.ranking_), ColName_U2R)))

# R2L
RankFeatures.fit(X_TrainR2LNew, Y_TrainR2L)

print ("R2L Features based on their rank:")
print (sorted(zip(map(lambda x: round(x, 4), RankFeatures.ranking_), ColName_R2L)))

"""## Choosing 13 Features among 122"""

FeatureEliminator = RFE(estimator=classifier, n_features_to_select=13, step=1)
FeatureEliminator.fit(X_TrainDos, Y_TrainDos)
X_rfeDos = FeatureEliminator.transform(X_TrainDos)

true=FeatureEliminator.support_
RFEColumnIndex_Dos=[i for i, x in enumerate(true) if x]
RFEColName_Dos=list( TrainColumnNames[i] for i in RFEColumnIndex_Dos)

FeatureEliminator.fit(X_TrainProbe, Y_TrainProbe)
X_rfeProbe = FeatureEliminator.transform(X_TrainProbe)
true=FeatureEliminator.support_
RFEColumnIndex_Probe = [i for i, x in enumerate(true) if x]
RFEColName_Probe=list( TrainColumnNames[i] for i in RFEColumnIndex_Probe)

FeatureEliminator.fit(X_TrainU2R, Y_TrainU2R)
X_rfeU2R = FeatureEliminator.transform(X_TrainU2R)
true=FeatureEliminator.support_
RFEColumnIndex_U2R = [i for i, x in enumerate(true) if x]
RFEColName_U2R = list( TrainColumnNames[i] for i in RFEColumnIndex_U2R)

FeatureEliminator.fit(X_TrainR2L, Y_TrainR2L)
X_rfeR2L = FeatureEliminator.transform(X_TrainR2L)
true=FeatureEliminator.support_
RFEColumnIndex_R2L = [i for i, x in enumerate(true) if x]
RFEColName_R2L = list( TrainColumnNames[i] for i in RFEColumnIndex_R2L)

print('Features selected for Dos:')
print(RFEColName_Dos)
print()

print('Features selected for Probe:')
print(RFEColName_Probe)
print()

print('Features selected for R2L:')
print(RFEColName_R2L)
print()

print('Features selected for U2R:')
print(RFEColName_U2R)

print(X_rfeDos.shape)
print(X_rfeProbe.shape)
print(X_rfeR2L.shape)
print(X_rfeU2R.shape)

"""# Step4: Building the Model"""

from __future__ import print_function
import numpy as np
np.random.seed(1337)  # for reproducibility

from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Lambda
from keras.layers import Embedding
from keras.layers import Convolution1D,MaxPooling1D, Flatten
from keras.datasets import imdb
from keras import backend as K
from sklearn.model_selection import train_test_split
import pandas as pd
from keras.utils.np_utils import to_categorical
from sklearn.preprocessing import OneHotEncoder

from sklearn.preprocessing import Normalizer
from keras.models import Sequential
from keras.layers import Convolution1D,Convolution2D, Dense, Dropout, Flatten, MaxPooling1D,MaxPooling2D
from keras.utils import np_utils
import numpy as np
import h5py
from keras import callbacks
from keras.layers import LSTM, GRU, SimpleRNN
from keras.callbacks import CSVLogger
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger

!ls

y_train = np.array(res_train_y)
y_test = np.array(res_test_y)
y_true = y_test

X_TrainDosNew.shape

# reshape input to be [samples, time steps, features]
X_train = np.reshape(res_train_an, (res_train_an.shape[0],11,11))
X_test = np.reshape(res_test_an, (res_test_an.shape[0],11,11))
X_train.shape

lstm_output_size = 35
lstm_output_size_final=25

cnn = Sequential()
cnn.add(Convolution2D(64, 3, border_mode="same",activation="relu",input_shape=(11, 11)))
cnn.add(MaxPooling2D(pool_length=(2)))
cnn.add(Convolution2D(16, 2, border_mode="same",activation="relu",input_shape=(5, 5)))
cnn.add(MaxPooling2D(pool_length=(2)))

cnn.add(LSTM(lstm_output_size,return_sequences=True))
cnn.add(Dropout(0.2))
cnn.add(LSTM(lstm_output_size_final))
cnn.add(Dropout(0.2))
cnn.add(Dense(5, activation="softmax"))

# define optimizer and objective, compile cnn

cnn.compile(loss="sparse_categorical_crossentropy", optimizer="adam",metrics=['accuracy'])

checkpointer = callbacks.ModelCheckpoint(filepath="results/cnn1results/checkpoint-{epoch:02d}.hdf5", verbose=1, save_best_only=True, monitor='val_acc',mode='max')
csv_logger = CSVLogger('results/cnn1results/cnntrainanalysis1.csv',separator=',', append=False)
history=cnn.fit(X_train, y_train, nb_epoch=10, validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])
cnn.save("results/cnn1results/cnn_model.hdf5")

cnn.load_weights("results/cnn1results/checkpoint-01.hdf5")







cnn.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
loss, accuracy = cnn.evaluate(X_test, y_test)
print("\nLoss: %.2f, Accuracy: %.2f%%" % (loss, accuracy*100))

# Retrieve a list of accuracy results on training and validation data
# sets for each training epoch

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

# Retrieve a list of list results on training and validation data
# sets for each training epoch
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))

# Plot training and validation accuracy per epoch
plt.plot(epochs, acc)
plt.plot(epochs, val_acc)
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.title('Training and validation accuracy')

plt.show()

# Plot training and validation loss per epoch
plt.plot(epochs, loss)
plt.plot(epochs, val_loss)
plt.title('Training and validation loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)
y_pred = cnn.predict_classes(X_test)
accuracy = accuracy_score(y_test, y_pred)
recall = recall_score(y_test, y_pred , average="weighted")
precision = precision_score(y_test, y_pred , average="weighted")
f1 = f1_score(y_test, y_pred, average="weighted")

print("confusion matrix")
print("----------------------------------------------")
print("accuracy")
print("%.6f" %accuracy)
print("recall")
print("%.6f" %recall)
print("precision")
print("%.6f" %precision)
print("f1score")
print("%.6f" %f1)
cm = sklearn.metrics.confusion_matrix(y_test, y_pred)
print("==============================================")

import matplotlib.pyplot as plt
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    import itertools
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

from sklearn.metrics import confusion_matrix
cnf_matrix = confusion_matrix(y_true, y_pred,labels=[0,1,2,3,4])
np.set_printoptions(precision=2)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=['Normal', 'Dos', 'Probe','R2L','U2R'],
                      title='Confusion matrix, without normalization')

normal 38479 295 30 26 14
dos 1766 5417 198 35 44
probe 605 254 1402 109 51
r2l 2001 34 28 787 35
u2r 38 1 1 1 26

cnf_matrix.print_stats()

FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)
FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)
TP = np.diag(cnf_matrix)
TN = cnf_matrix.values.sum() - (FP + FN + TP)

# Sensitivity, hit rate, recall, or true positive rate
Detection_Rate = TP/(TP+FN)
Detection_Rate

import pylab as plt
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
langs = ['J48', 'Naive Bayes', 'NB Tree', 'Random Forest', 'Random Tree','Multi-Layer Perceptron','SVM','RNN','CNN-LSTM']
students = [74.60,74.40,75.40,74.00,72.80,78.10,74.00,81.29,89.23]
ax.bar(langs,students)
plt.show()
LABELS = ["Monday", "Tuesday", "Wednesday"]

plt.bar(DayOfWeekOfCall, DispatchesOnThisWeekday, align='center')
plt.xticks(DayOfWeekOfCall, LABELS)
plt.show()

import matplotlib.pyplot as plt; plt.rcdefaults()
import numpy as np
import matplotlib.pyplot as plt

objects = ('J48', 'Naive Bayes', 'NB Tree', 'Random Forest', 'Random Tree','Multi-Layer Perceptron','SVM','RNN','CNN-LSTM')
y_pos = np.arange(len(objects))
performance = [74.60,74.40,75.40,74.00,72.80,78.10,74.00,81.29,89.23]

plt.barh(y_pos, performance, align='center', alpha=0.5)
plt.yticks(y_pos, objects)
plt.xlabel('ACs')
plt.title('ACs of Multiple Algorithms used for Intrusion Detection')

plt.show()

import numpy as np
import matplotlib.pyplot as plt

# data to plot
n_groups = 4
means_frank = (83.49, 83.40, 24.69, 11.55)
means_guido = (87.30, 85.43, 30.21, 11.29)

# create plot
fig, ax = plt.subplots()
index = np.arange(n_groups)
bar_width = 0.35
opacity = 0.8

rects1 = plt.bar(index, means_frank, bar_width,
alpha=opacity,
color='b',
label='RNN')

rects2 = plt.bar(index + bar_width, means_guido, bar_width,
alpha=opacity,
color='g',
label='CNN-LSTM')

plt.xlabel('Different types of attacks')
plt.ylabel('Detection Rate')
plt.title('Detection Rate (CNN-LSTM vs RNN)')
plt.xticks(index + bar_width, ('DoS', 'Probe', 'R2L', 'U2R'))
plt.legend()

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# data to plot
n_groups = 4
means_frank = (2.06, 2.16, 0.8,0.07)
means_guido = (1.32, 1.41, 0.65, 0.1)

# create plot
fig, ax = plt.subplots()
index = np.arange(n_groups)
bar_width = 0.35
opacity = 0.8

rects1 = plt.bar(index, means_frank, bar_width,
alpha=opacity,
color='b',
label='RNN')

rects2 = plt.bar(index + bar_width, means_guido, bar_width,
alpha=opacity,
color='g',
label='CNN-LSTM')

plt.xlabel('Different types of attacks')
plt.ylabel('False Alarm Rate')
plt.title('False Alarm Rate (CNN-LSTM vs RNN)')
plt.xticks(index + bar_width, ('DoS', 'Probe', 'R2L', 'U2R'))
plt.legend()

plt.tight_layout()
plt.show()

# Considering all features
DosClassifier = DecisionTreeClassifier(random_state=0)
ProbeClassifier = DecisionTreeClassifier(random_state=0)
R2LClassifier = DecisionTreeClassifier(random_state=0)
U2RClassifier = DecisionTreeClassifier(random_state=0)
DosClassifier.fit(X_TrainDos, Y_TrainDos)
ProbeClassifier.fit(X_TrainProbe, Y_TrainProbe)
R2LClassifier.fit(X_TrainR2L, Y_TrainR2L)
U2RClassifier.fit(X_TrainU2R, Y_TrainU2R)

# selected Features
DosClassifier_RFE = DecisionTreeClassifier(random_state=0)
ProbeClassifier_RFE = DecisionTreeClassifier(random_state=0)
R2LClassifier_RFE = DecisionTreeClassifier(random_state=0)
U2RClassifier_RFE = DecisionTreeClassifier(random_state=0)
DosClassifier_RFE.fit(X_rfeDos, Y_TrainDos)
ProbeClassifier_RFE.fit(X_rfeProbe, Y_TrainProbe)
R2LClassifier_RFE.fit(X_rfeR2L, Y_TrainR2L)
U2RClassifier_RFE.fit(X_rfeU2R, Y_TrainU2R)

"""# Step 5: Prediction (Results)"""

DosClassifier.predict(X_TestDos)

DosClassifier.predict_proba(X_TestDos)[0:10]

Y_PredDos = DosClassifier.predict(X_TestDos)
pd.crosstab(Y_TestDos, Y_PredDos, rownames=['Actual attacks'], colnames=['Predicted attacks'])

Y_PredProbe = ProbeClassifier.predict(X_TestProbe)
pd.crosstab(Y_TestProbe, Y_PredProbe, rownames=['Actual attacks'], colnames=['Predicted attacks'])

Y_PredR2L = R2LClassifier.predict(X_TestR2L)
pd.crosstab(Y_TestR2L, Y_PredR2L, rownames=['Actual attacks'], colnames=['Predicted attacks'])

Y_PredU2R = U2RClassifier.predict(X_TestU2R)
pd.crosstab(Y_TestU2R, Y_PredU2R, rownames=['Actual attacks'], colnames=['Predicted attacks'])

"""## Cross Validation"""

from sklearn.model_selection import cross_val_score
from sklearn import metrics

print("Scores of Dos:")

accuracy = cross_val_score(DosClassifier, X_TestDos, Y_TestDos, cv = 10, scoring = 'accuracy')
print("Accuracy: %0.5f (+/- %0.5f)" % (accuracy.mean(), accuracy.std() * 2))

precision = cross_val_score(DosClassifier, X_TestDos, Y_TestDos, cv = 10, scoring='precision')
print("Precision: %0.5f (+/- %0.5f)" % (precision.mean(), precision.std() * 2))

recall = cross_val_score(DosClassifier, X_TestDos, Y_TestDos, cv = 10, scoring='recall')
print("Recall: %0.5f (+/- %0.5f)" % (recall.mean(), recall.std() * 2))

f = cross_val_score(DosClassifier, X_TestDos, Y_TestDos, cv = 10, scoring='f1')
print("F-measure: %0.5f (+/- %0.5f)" % (f.mean(), f.std() * 2))

print("Scores of Probe:")

accuracy = cross_val_score(ProbeClassifier, X_TestProbe, Y_TestProbe, cv = 10, scoring = 'accuracy')
print("Accuracy: %0.5f (+/- %0.5f)" % (accuracy.mean(), accuracy.std() * 2))

precision = cross_val_score(ProbeClassifier, X_TestProbe, Y_TestProbe, cv = 10, scoring='precision_macro')
print("Precision: %0.5f (+/- %0.5f)" % (precision.mean(), precision.std() * 2))

recall = cross_val_score(ProbeClassifier, X_TestProbe, Y_TestProbe, cv = 10, scoring='recall_macro')
print("Recall: %0.5f (+/- %0.5f)" % (recall.mean(), recall.std() * 2))

f = cross_val_score(ProbeClassifier, X_TestProbe, Y_TestProbe, cv = 10, scoring='f1_macro')
print("F-measure: %0.5f (+/- %0.5f)" % (f.mean(), f.std() * 2))

print("Scores of R2L:")

accuracy = cross_val_score(R2LClassifier, X_TestR2L, Y_TestR2L, cv = 10, scoring = 'accuracy')
print("Accuracy: %0.5f (+/- %0.5f)" % (accuracy.mean(), accuracy.std() * 2))

precision = cross_val_score(R2LClassifier, X_TestR2L, Y_TestR2L, cv = 10, scoring='precision_macro')
print("Precision: %0.5f (+/- %0.5f)" % (precision.mean(), precision.std() * 2))

recall = cross_val_score(R2LClassifier, X_TestR2L, Y_TestR2L, cv = 10, scoring='recall_macro')
print("Recall: %0.5f (+/- %0.5f)" % (recall.mean(), recall.std() * 2))

f = cross_val_score(R2LClassifier, X_TestR2L, Y_TestR2L, cv = 10, scoring='f1_macro')
print("F-measure: %0.5f (+/- %0.5f)" % (f.mean(), f.std() * 2))

print("Scores of U2R:")

accuracy = cross_val_score(U2RClassifier, X_TestU2R, Y_TestU2R, cv = 10, scoring = 'accuracy')
print("Accuracy: %0.5f (+/- %0.5f)" % (accuracy.mean(), accuracy.std() * 2))

precision = cross_val_score(U2RClassifier, X_TestU2R, Y_TestU2R, cv = 10, scoring='precision_macro')
print("Precision: %0.5f (+/- %0.5f)" % (precision.mean(), precision.std() * 2))

recall = cross_val_score(U2RClassifier, X_TestU2R, Y_TestU2R, cv = 10, scoring='recall_macro')
print("Recall: %0.5f (+/- %0.5f)" % (recall.mean(), recall.std() * 2))

f = cross_val_score(U2RClassifier, X_TestU2R, Y_TestU2R, cv = 10, scoring='f1_macro')
print("F-measure: %0.5f (+/- %0.5f)" % (f.mean(), f.std() * 2))

"""### RFECV"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

print(__doc__)

import matplotlib.pyplot as plt
from sklearn.feature_selection import RFECV
from sklearn.model_selection import StratifiedKFold

RFECV_Dos = RFECV(estimator=DosClassifier, step=1, cv=10, scoring='accuracy')
RFECV_Dos.fit(X_TestDos, Y_TestDos)

# Plot number of features VS. cross-validation scores
plt.figure()
plt.xlabel("Number of features selected")
plt.ylabel("Cross validation score (no. of correct classifications)")
plt.title('RFECV Dos')
plt.plot(range(1, len(RFECV_Dos.grid_scores_) + 1), RFECV_Dos.grid_scores_)
plt.show()

RFECV_Probe = RFECV(estimator=ProbeClassifier, step=1, cv=10, scoring='accuracy')
RFECV_Probe.fit(X_TestProbe, Y_TestProbe)

# Plot number of features VS. cross-validation scores
plt.figure()
plt.xlabel("Number of features selected")
plt.ylabel("Cross validation score (no. of correct classifications)")
plt.title('RFECV Probe')
plt.plot(range(1, len(RFECV_Probe.grid_scores_) + 1), RFECV_Probe.grid_scores_)
plt.show()

RFECV_R2L = RFECV(estimator=R2LClassifier, step=1, cv=10, scoring='accuracy')
RFECV_R2L.fit(X_TestR2L, Y_TestR2L)

# Plot number of features VS. cross-validation scores
plt.figure()
plt.xlabel("Number of features selected")
plt.ylabel("Cross validation score (no. of correct classifications)")
plt.title('RFECV R2L')
plt.plot(range(1, len(RFECV_R2L.grid_scores_) + 1), RFECV_R2L.grid_scores_)
plt.show()

RFECV_U2R = RFECV(estimator=U2RClassifier, step=1, cv=10, scoring='accuracy')
RFECV_U2R.fit(X_TestU2R, Y_TestU2R)

# Plot number of features VS. cross-validation scores
plt.figure()
plt.xlabel("Number of features selected")
plt.ylabel("Cross validation score (no. of correct classifications)")
plt.title('RFECV Dos')
plt.plot(range(1, len(RFECV_U2R.grid_scores_) + 1), RFECV_U2R.grid_scores_)
plt.show()



